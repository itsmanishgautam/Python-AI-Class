{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "# Initialize an empty list to store URLs\n",
    "urls = []\n",
    "\n",
    "# # Iterate over pages 1 to 13\n",
    "# for page_num in range(1, 14):\n",
    "url = 'https://www.jobsnepal.com/jobs?page=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = urllib.request.Request(url, headers={'User-Agent': user_agent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urllib.request.urlopen(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = response.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all <div class=\"col-md-8 px-0 top-content\"> elements\n",
    "alldata = soup.find_all('div', class_='col-md-8 px-0 top-content')\n",
    "# print(alldata)\n",
    "\n",
    "# # Print or process each found <div> element and its content\n",
    "# for div in alldata:\n",
    "#     print(div.prettify())  # Print the entire <div> and its nested HTML content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract <h2 class=\"job-title\" title=\"Interpreter, Translator, Bridge Engineer, Highway Engineer, HSE, Civil Engineer, Office Staff\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Software \\ufeffQA Engineer Testing', 'Software Developer Dot Net', 'Interpreter, Translator, Bridge Engineer, Highway Engineer, HSE, Civil Engineer, Office Staff', 'Expression of Interest to Conduct Training of Trainers (TOT)', 'Admin Associate', 'बाख्रा आपुर्ति सम्बन्धि टेण्डर आह्वान गरिएको सूचना', 'Call for Proposal for consultancy service', 'Individual Consultant - Capacity Building Officer', 'Province Director', 'Various', 'Crew Member (All-rounder)', 'Administrative Officer']\n"
     ]
    }
   ],
   "source": [
    "# Find all <h2> elements with the class 'job-title'\n",
    "title = soup.find_all('h2', class_='job-title')\n",
    "\n",
    "# Extract the text content from each <h2> element\n",
    "job_title = [\n",
    "    h2.text.strip() for h2 in title]\n",
    "\n",
    "# Print the extracted text content\n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CodeBee Nepal Pvt. Ltd.(Sister Concern Of WallBee APS)', 'CodeBee Nepal Pvt. Ltd.(Sister Concern Of WallBee APS)', 'Poly Changda Engineering Company', 'Access Planet Organization', 'Bagmati Welfare Society Nepal(BWSN)', 'CEAD Nepal Doti', 'Association of Community Radio Broadcasters Nepal', 'UNDP', 'KIRDARC-Nepal', 'Vijay Motors Pvt. Ltd.', 'JobsNepal.com Direct Recruitment Service', 'JobsNepal.com Direct Recruitment Service']\n"
     ]
    }
   ],
   "source": [
    "# Find all <a> tags within the specified <div> elements\n",
    "data = soup.find_all('div', class_='card-inner')\n",
    "\n",
    "# Extract the 'title' attribute from each <a> tag\n",
    "company = [a.find('a').get('title') for a in data]\n",
    "\n",
    "# Print the extracted titles\n",
    "print(company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location and Category Yet to Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It print Both Location and Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kathmandu', 'Engineering - Software, Software Development', 'Kathmandu', 'Engineering - Software, Software Development', 'Terai Region', 'Engineering - Civil, Engineering - Structural, Office Assistant', 'Rupandehi', 'Development and Project, Expression of Interests, Tender Notice, Bid', 'Sarlahi', 'Administrative / Management, Development and Project', 'Doti', 'Development and Project, Expression of Interests, Tender Notice, Bid, Development / NGO', 'Lalitpur', 'Development and Project, Expression of Interests, Tender Notice, Bid', 'Okhaldhunga', 'Development and Project, Environment and climate', 'Birendranagar Surkhet', 'Education, Social Science, Development and Project', 'Kathmandu', 'Automotive / Automobiles', 'Kathmandu', 'Hospitality / Hotel', 'Kathmandu', 'Administrative / Management']\n"
     ]
    }
   ],
   "source": [
    "# Find all <div> elements with both classes \"icon-price-tags\" and \"d-flex align-items-center pl-1 pr-1 py-1\"\n",
    "data = soup.find_all('div', class_=['icon-price-tags mr-2 text-success icon-sm', 'd-flex align-items-center pl-1 pr-1 py-1'])\n",
    "\n",
    "# Extract the text content from each <div> element\n",
    "doubledata = [div.find('div').text.strip() for div in data]\n",
    "\n",
    "# Print the extracted categories\n",
    "print(doubledata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations: ['Kathmandu', 'Kathmandu', 'Terai Region', 'Rupandehi', 'Sarlahi', 'Doti', 'Lalitpur', 'Okhaldhunga', 'Birendranagar Surkhet', 'Kathmandu', 'Kathmandu', 'Kathmandu']\n",
      "Categories: ['Engineering - Software, Software Development', 'Engineering - Software, Software Development', 'Engineering - Civil, Engineering - Structural, Office Assistant', 'Development and Project, Expression of Interests, Tender Notice, Bid', 'Administrative / Management, Development and Project', 'Development and Project, Expression of Interests, Tender Notice, Bid, Development / NGO', 'Development and Project, Expression of Interests, Tender Notice, Bid', 'Development and Project, Environment and climate', 'Education, Social Science, Development and Project', 'Automotive / Automobiles', 'Hospitality / Hotel', 'Administrative / Management']\n"
     ]
    }
   ],
   "source": [
    "# Separate locations and categories\n",
    "locations = doubledata[::2]\n",
    "categories = doubledata[1::2]\n",
    "\n",
    "# Print the separated locations and categories\n",
    "print(\"Locations:\", locations)\n",
    "print(\"Categories:\", categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to job_data10.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a list of tuples containing job titles and companies\n",
    "data = list(zip(job_title, company,locations,categories))\n",
    "import csv\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = 'job_data10.csv'\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Job Title', 'Company', 'Location', 'Category'])  # Write header row\n",
    "    writer.writerows(data)  # Write data rows\n",
    "\n",
    "print(f'Data exported to {csv_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
