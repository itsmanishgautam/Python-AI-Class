{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First  Work one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import re\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Function to format date string\n",
    "# def format_date(date):\n",
    "#     return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # Define the URL and headers\n",
    "# url = \"https://www.sharesansar.com/ajaxtodayshareprice\"\n",
    "# headers = {\n",
    "#     \"accept\": \"*/*\",\n",
    "#     \"accept-language\": \"en-GB,en-US;q=0.9,en;q=0.8\",\n",
    "#     \"content-type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "#     \"cookie\": \"_gid=GA1.2.317488179.1716993804; _ga=GA1.2.1019898196.1716993802; _gat_gtag_UA_24700594_1=1; XSRF-TOKEN=eyJpdiI6IkROZXZNdG5VMVVxSDF5SzFHZFI2R2c9PSIsInZhbHVlIjoiVCtjdDdNY0lzODZXT1JJQTI0ZTZxWWpveU5LOXIxQzZoMlljdWd6eHZSWXEyTkhyZ1NNSWhEUmhFWjJWWGtkRWNzTnVVNmRqeDYzdFZuaGFycyszSmdnd2NkZHpIOHpkR3ZyMWNDSmFHaHVtcUFreGpGa0htaC92N3BRZHNRb3ciLCJtYWMiOiI3OTAzNWFkMzcwODgxNGIyNjM3YWQ3YjVjYzYyOTJmZDY5YTgwODM1MTQ0OThiMmUyNzRjNzRkNTQxZDVlODRkIn0%3D; sharesansar_session=eyJpdiI6InpybnRHeFlQOEltdXY2UjRjbFIrNlE9PSIsInZhbHVlIjoiajMyVWJ3NFNqbEdKRUpRWEp6ZUF6WEJCc3BRL0NjMzAwL1FHTm05OHlPVXVqWVl2dDFwL0lOWU9TbGhyRWZ0VmtjUWVJT3NndWZSNlFzaURoTS9FWkNad2hQaHlxSkRhWnJDQUJjdDVRTnczT25kaE5mazVOcnNkK1FvWkx2MjUiLCJtYWMiOiI1NzNkNmZkYmNkMTY5MTk0YjM0YzA1NzZmNmMxNWZmNjUwNWU1YWE2M2FlOGIwMjgyNjRhZTQxZjFjOGU3ZjYyIn0%3D; _ga_FPXFBP3MT9=GS1.1.1717006970.4.1.1717007009.21.0.0\",\n",
    "#     \"dnt\": \"1\",\n",
    "#     \"origin\": \"https://www.sharesansar.com\",\n",
    "#     \"priority\": \"u=1, i\",\n",
    "#     \"referer\": \"https://www.sharesansar.com/today-share-price\",\n",
    "#     \"sec-ch-ua\": \"\\\"Google Chrome\\\";v=\\\"125\\\", \\\"Chromium\\\";v=\\\"125\\\", \\\"Not.A/Brand\\\";v=\\\"24\\\"\",\n",
    "#     \"sec-ch-ua-mobile\": \"?1\",\n",
    "#     \"sec-ch-ua-platform\": \"\\\"Android\\\"\",\n",
    "#     \"sec-fetch-dest\": \"empty\",\n",
    "#     \"sec-fetch-mode\": \"cors\",\n",
    "#     \"sec-fetch-site\": \"same-origin\",\n",
    "#     \"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Mobile Safari/537.36\",\n",
    "#     \"x-requested-with\": \"XMLHttpRequest\"\n",
    "# }\n",
    "\n",
    "\n",
    "# # Define the fixed date\n",
    "# user_input = input(\"Enter the date in AD in format: 2024-05-29: \")\n",
    "\n",
    "# fixed_date = datetime.strptime(user_input, \"%Y-%m-%d\")\n",
    "\n",
    "# # Prepare the data payload for the specific date\n",
    "# data = {\n",
    "#     \"_token\": \"6yQ3oSYHtCuBgz6cCZsReEbk6OpFp4mYaxppSE5i\",\n",
    "#     \"sector\": \"all_sec\",\n",
    "#     \"date\": format_date(fixed_date)\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# # Make the POST request\n",
    "# response = requests.post(url, headers=headers, data=data)\n",
    "\n",
    "# # Check the response status\n",
    "# if response.status_code == 200:\n",
    "#     response_html = response.text\n",
    "#     print(\"Response for\", data['date'], \":\")\n",
    "#     # print(response_html)\n",
    "# else:\n",
    "#     print(\"Request failed for\", format_date(fixed_date), \"with status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<style>\n",
      ".light-blue {\n",
      "    background-color: #d6eef8;\n",
      "}\n",
      "</style>\n",
      "<h5>As of : <span class=\"text-org\">2024-01-20</span>\n",
      "</h5>\n",
      "<div class=\"headFixedWrapper\">\n",
      "    <table id=\"headFixed\" class=\"table table-bordered table-striped table-hover dataTable compact\">\n",
      "        <thead>\n",
      "            <tr>\n",
      "                <th width=\"10px\">S.No</th>\n",
      "                <th>Symbol</th>\n",
      "                <th class=\"text-center\" title=\"Stock Confidence\">Conf.</th>\n",
      "                <th class=\"text-center\">Open</th>\n",
      "                <th class=\"text-center\">High</th>\n",
      "                <th class=\"text-center\">Low</th>\n",
      "                <th class=\"text-center\">Close</th>\n",
      "                <th class=\"text-center\">VWAP</th>\n",
      "                <th class=\"text-center\">Vol</th>\n",
      "                <th class=\"text-center\">Prev. Close</th>\n",
      "                <th class=\"text-center\">Turnover</th>\n",
      "                <th class=\"text-center\">Trans.</th>\n",
      "                <th class=\"text-center\">Diff</th>\n",
      "                <th class=\"text-center\">Range</th>\n",
      "                <th class=\"text-center\">Diff %</th>\n",
      "                <th class=\"text-center\">Range %</th>\n",
      "                <th class=\"text-center\">VWAP %</th>\n",
      "                <th class=\"text-center\">52 Weeks High</th>\n",
      "                <th class=\"text-center\">52 Weeks Low</th>\n",
      "            </tr>\n",
      "        </thead>\n",
      "        <tbody>\n",
      "                        <tr>\n",
      "                <td colspan=\"19\" class=\"text-center\"> No Record Found.</td>\n",
      "            </tr>\n",
      "                    </tbody>\n",
      "    </table>\n",
      "</div>\n",
      "<br>\n",
      "<div class=\"pull-right\">\n",
      "    <h4 class=\"text-right\"><b>Total number of Compaines: 0</b></h4>\n",
      "    <h4 class=\"text-right\"><b>Total Traded Shares: 0.00</b></h4>\n",
      "    <h4 class=\"text-right\"><b>Total Turnover : Rs 0.00</b></h4>\n",
      "    <br>\n",
      "    <br>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Get the HTML page and extract the CSRF token\n",
    "session = requests.Session()\n",
    "get_url = \"https://www.sharesansar.com/today-share-price\"\n",
    "response = session.get(get_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML to find the CSRF token\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    token = soup.find('input', {'name': '_token'})['value']\n",
    "else:\n",
    "    print(\"Failed to retrieve the CSRF token.\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Send the POST request using the extracted CSRF token\n",
    "post_url = \"https://www.sharesansar.com/ajaxtodayshareprice\"\n",
    "headers = {\n",
    "    \"sec-ch-ua\": \"\\\"Google Chrome\\\";v=\\\"125\\\", \\\"Chromium\\\";v=\\\"125\\\", \\\"Not.A/Brand\\\";v=\\\"24\\\"\",\n",
    "    \"DNT\": \"1\",\n",
    "    \"sec-ch-ua-mobile\": \"?1\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Mobile Safari/537.36\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Referer\": \"https://www.sharesansar.com/today-share-price\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "    \"sec-ch-ua-platform\": \"\\\"Android\\\"\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# # Function to format date string\n",
    "def format_date(date):\n",
    "    return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # Define the fixed date\n",
    "user_input = input(\"Enter the date in AD in format: 2024-05-29: \")\n",
    "\n",
    "fixed_date = datetime.strptime(user_input, \"%Y-%m-%d\")\n",
    "\n",
    "# # Prepare the data payload for the specific date\n",
    "\n",
    "data = {\n",
    "    \"_token\": token,\n",
    "    \"sector\": \"all_sec\",\n",
    "    \"date\": format_date(fixed_date)\n",
    "}\n",
    "\n",
    "\n",
    "# # Make the POST request\n",
    "response = requests.post(post_url, headers=headers, data=data)\n",
    "\n",
    "# # Check the response status\n",
    "# if response.status_code == 200:\n",
    "#     response_html = response.text\n",
    "#     print(\"Response for\", data['date'], \":\")\n",
    "#     # print(response_html)\n",
    "# else:\n",
    "#     print(\"Request failed for\", format_date(fixed_date), \"with status code:\", response.status_code)\n",
    "\n",
    "response = session.post(post_url, headers=headers, data=data)\n",
    "response_html = response.text\n",
    "print(response_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_Head: ['S.No', 'Symbol', 'Conf.', 'Open', 'High', 'Low', 'Close', 'VWAP', 'Vol', 'Prev. Close', 'Turnover', 'Trans.', 'Diff', 'Range', 'Diff %', 'Range %', 'VWAP %', '52 Weeks High', '52 Weeks Low']\n"
     ]
    }
   ],
   "source": [
    "# Extracting data within <thead> tags from both tables\n",
    "import re\n",
    "thead_pattern = r'<thead>(.*?)</thead>'\n",
    "thead_data = re.findall(thead_pattern, response_html, re.DOTALL)              \n",
    "\n",
    "head_data_all = []\n",
    "\n",
    "# Iterate over each element of thead_data and extract data within <th> tags\n",
    "for data in thead_data:\n",
    "    head_data = re.findall(r'<th.*?>(.*?)</th>', data, re.DOTALL)\n",
    "    head_data_all.extend(head_data)\n",
    "\n",
    "print(\"T_Head:\", head_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBody: [' No Record Found.']\n"
     ]
    }
   ],
   "source": [
    "# Extracting data within <tbody> tags\n",
    "import re\n",
    "tbody_pattern = r'<tbody>(.*?)</tbody>'\n",
    "tbody_data = re.findall(tbody_pattern, response_html, re.DOTALL)              \n",
    "\n",
    "matches_data_all = []\n",
    "\n",
    "# Iterate over each element of tbody_data and extract data within <td> tags\n",
    "for data in tbody_data:\n",
    "    matches_data = re.findall(r'<td.*?>(.*?)</td>', data, re.DOTALL)\n",
    "    matches_data_all.extend(matches_data)\n",
    "\n",
    "print(\"TBody:\", matches_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[[' No Record Found.']]\n"
     ]
    }
   ],
   "source": [
    "num_columns = len(head_data_all)\n",
    "print(len(head_data_all))\n",
    "\n",
    "# Split the data into sublists for each row\n",
    "sublists = [matches_data_all[i:i+num_columns] for i in range(0, len(matches_data_all), num_columns)]\n",
    "print(sublists)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# List to store company names\n",
    "company_names = []\n",
    "\n",
    "# Regular expression pattern to match the title attribute\n",
    "company_pattern = r'title=\"([^\"]+)\"'\n",
    "\n",
    "# Loop through each sublist and extract company names\n",
    "for sublist in sublists:\n",
    "    for item in sublist:\n",
    "        match = re.search(company_pattern, item)\n",
    "        if match:\n",
    "            company_names.append(match.group(1))\n",
    "\n",
    "print(company_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Record Found\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# List to store company names\n",
    "company_names = []\n",
    "\n",
    "# Regular expression pattern to match the title attribute\n",
    "company_pattern = r'title=\"([^\"]+)\"'\n",
    "\n",
    "# Loop through each sublist and extract company names\n",
    "for sublist in sublists:\n",
    "    for item in sublist:\n",
    "        match = re.search(company_pattern, item)\n",
    "        if match:\n",
    "            company_names.append(match.group(1))\n",
    "\n",
    "# Function to extract symbol from HTML anchor tag\n",
    "def extract_symbol(html):\n",
    "    name_match = re.search(r'>([^<]+)<', html)\n",
    "    symbol = name_match.group(1) if name_match else None\n",
    "    return symbol\n",
    "\n",
    "\n",
    "# Convert sublists to list of dictionaries\n",
    "data = []\n",
    "\n",
    "if sublists == [[' No Record Found.']]:\n",
    "    print(\"No Record Found\")\n",
    "else:\n",
    "    for i, sublist in enumerate(sublists):\n",
    "        symbol = extract_symbol(sublist[1])\n",
    "        entry = {head_data_all[0]: sublist[0], head_data_all[1]: symbol}\n",
    "        entry.update(dict(zip(head_data_all[2:], sublist[2:])))\n",
    "        entry['Company Name'] = company_names[i]\n",
    "        data.append(entry)\n",
    "\n",
    "\n",
    "    file_name = f\"csv/share_Bazar_{format_date(fixed_date)}.csv\"\n",
    "\n",
    "    # Write data to CSV\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=head_data_all + ['Company Name'])\n",
    "        # Write header\n",
    "        writer.writeheader()\n",
    "        # Write rows\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"Data has been written to {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the file name\n",
    "# import csv\n",
    "# file_name = f\"data_{format_date(fixed_date)}.csv\"\n",
    "\n",
    "# # Write data to CSV\n",
    "# with open(file_name, mode='w', newline='') as file:\n",
    "#     writer = csv.DictWriter(file, fieldnames=head_data_all + ['URL', 'Company Name', 'Title'])\n",
    "#     # Write header\n",
    "#     writer.writeheader()\n",
    "#     # Write rows\n",
    "#     for row in data:\n",
    "#         writer.writerow(row)\n",
    "\n",
    "# print(f\"Data has been written to {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
