{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a Course at Random First**:\n",
    "   This step involves generating a course randomly. Without more context, it's unclear what kind of course you're referring to. However, you would need to generate some data representing a course, which could include fields like course name, course code, instructor, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "def generate_fake_courses(num_records):\n",
    "    courses = ['Java', 'Python', 'PHP', 'C#']  # List of available courses\n",
    "\n",
    "    with open('csv/Courses.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Course']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for _ in range(num_records):\n",
    "            writer.writerow({'Course': random.choice(courses)})  # Choose a random course from the list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_records = 100000\n",
    "    generate_fake_courses(num_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate faker, merge faker and course, and split to three output**:\n",
    "   This step involves using Faker library to generate fake data, merging it with the course data generated in the first step, and then splitting the merged data into three output files. The specifics of how to merge and split the data depend on the structure of your data and your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake data generated and CSV file split completed.\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_fake_data(num_records):\n",
    "    with open('csv/fake_data.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Name', 'Contact', 'Country', 'CountryCode']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for _ in range(num_records):\n",
    "            writer.writerow({\n",
    "                'Name': fake.name(),\n",
    "                'Contact': fake.phone_number(),\n",
    "                'Country': fake.country(),\n",
    "                'CountryCode': fake.country_code()\n",
    "            })\n",
    "\n",
    "\n",
    "def merge_csv(df1,df2):\n",
    "    merged_df = pd.concat([df1, df2], axis=1)\n",
    "    merged_df.to_csv(\"csv/merged_Courses_output.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "def split_csv(input_file):\n",
    "    output_files = ['csv/splitoutput1.csv', 'csv/splitoutput2.csv', 'csv/splitoutput3.csv']\n",
    "\n",
    "    writers = {}\n",
    "    for file_name in output_files:\n",
    "        writers[file_name] = csv.DictWriter(open(file_name, 'w', newline=''), fieldnames=['Country', 'Name', 'Contact', 'CountryCode', 'Course'])\n",
    "        writers[file_name].writeheader()\n",
    "\n",
    "    with open(input_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            output_file = random.choice(output_files)\n",
    "            writers[output_file].writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_records = 100000\n",
    "    generate_fake_data(num_records)\n",
    "\n",
    "    df1 = pd.read_csv(\"csv/fake_data.csv\")\n",
    "    df2 = pd.read_csv(\"csv/Courses.csv\")\n",
    "    merge_csv(df1,df2)\n",
    "\n",
    "    input_file = 'csv/merged_Courses_output.csv'\n",
    "    split_csv(input_file)\n",
    "    print(\"Fake data generated and CSV file split completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run NRB scrap and generate forex.csv**:\n",
    "   This step involves scraping data from NRB (presumably Nepal Rastra Bank) and generating a file named `forex.csv`. This file likely contains foreign exchange rate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to csv/forex.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "\n",
    "url ='https://www.nrb.org.np/forex/'\n",
    "request = urllib.request.Request(url, headers={'User-Agent': user_agent})\n",
    "response = urllib.request.urlopen(request)\n",
    "html_content = response.read().decode('utf-8')\n",
    "\n",
    "# Define the regex pattern\n",
    "currency_pattern = r'<div class=\"flag flag--...\"></div>\\s*<div class=\"ml-2 text-uppercase\">(.*?)\\s*<span\\s*class=\"text-capitalize\">\\(([^)]+)\\)</span>'\n",
    "\n",
    "# Find all matches in the HTML\n",
    "currency_matches = re.findall(currency_pattern, html_content) \n",
    "\n",
    "currency_code = [item[0] for item in currency_matches]\n",
    "currency_code = [code.upper() for code in currency_code]\n",
    "currency = [item[1] for item in currency_matches]\n",
    "\n",
    "data_pattern = r'<td>(.*?)</td>\\s*<td>(.*?)</td>\\s*<td>(.*?)</td>'\n",
    "# Find all matches in the HTML\n",
    "data_matches = re.findall(data_pattern, html_content) \n",
    "\n",
    "units = [item[0] for item in data_matches]\n",
    "buy = [item[1] for item in data_matches]\n",
    "sell = [item[2] for item in data_matches]\n",
    "\n",
    "# Create a list of tuples containing job titles and companies\n",
    "data = list(zip(currency_code,currency,units,buy,sell))\n",
    "import csv\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = 'csv/forex.csv'\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Currency_Code','Currency','Units','Buy','Sell'])  # Write header row\n",
    "    writer.writerows(data)  # Write data rows\n",
    "\n",
    "print(f'Data exported to {csv_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate: Data exported to csv/Country_and_CurrencyCode.csv**:\n",
    "   This step involves generating a file named `Country_and_CurrencyCode.csv`. The contents of this file are not specified, but it likely contains data relating to countries and currency codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to csv/Country_and_CurrencyCode.csv\n"
     ]
    }
   ],
   "source": [
    "url ='https://www.iban.com/currency-codes'\n",
    "request = urllib.request.Request(url, headers={'User-Agent': user_agent})\n",
    "response = urllib.request.urlopen(request)\n",
    "html_content = response.read().decode('utf-8')\n",
    "\n",
    "data_pattern = r'<td>(.*?)</td>\\s*<td>(.*?)</td>\\s*<td>(.*?)</td>\\s*<td>(.*?)</td>'\n",
    "# Find all matches in the HTML\n",
    "data_matches = re.findall(data_pattern, html_content) \n",
    "\n",
    "Country = [item[0] for item in data_matches]\n",
    "Currency = [item[1] for item in data_matches]\n",
    "Currency_Code = [item[2] for item in data_matches]\n",
    "numbers = [item[3] for item in data_matches]\n",
    "\n",
    "# Create a list of tuples containing job titles and companies\n",
    "data = list(zip( Currency_Code, Currency,Country))\n",
    "import csv\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = 'csv/Country_and_CurrencyCode.csv'\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Currency_Code','Currency','Country'])  # Write header row\n",
    "    writer.writerows(data)  # Write data rows\n",
    "\n",
    "print(f'Data exported to {csv_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge Forex_Country_Merged.py**:\n",
    "   This step involves running a Python script (`Forex_Country_Merged.py`) to merge `forex.csv` and `Country_and_CurrencyCode.csv` based on currency codes. The output of this merge is saved to a file named `CountryAdd_onCurrency_output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_complex(df3, df4, output_file):\n",
    "    merged_df = pd.merge(df4, df3, on=['Currency_Code'])\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df3 = pd.read_csv(\"csv/forex.csv\")\n",
    "    df4 = pd.read_csv(\"csv/Country_and_CurrencyCode.csv\")\n",
    "    output_file = 'csv/CountryAdd_onCurrency_output.csv'\n",
    "    merge_csv_complex(df3, df4, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge_all.py**:\n",
    "   This step involves running another Python script to perform multiple operations:\n",
    "   - Reorder the columns in the data to bring the \"Country\" column first.\n",
    "   - Convert the data to lowercase to ensure case-insensitive matching.\n",
    "   - Merge the reordered and lowercased data with other datasets.\n",
    "   - Export the final merged data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output Files Created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_complex(out1, out2, out3, mergedcsv1, output_file1, output_file2, output_file3):\n",
    "\n",
    "    # Convert \"Country\" column to lowercase for case-insensitive matching\n",
    "    mergedcsv1['Country'] = mergedcsv1['Country'].str.lower()\n",
    "    out1['Country'] = out1['Country'].str.lower()\n",
    "    out2['Country'] = out2['Country'].str.lower()\n",
    "    out3['Country'] = out3['Country'].str.lower()\n",
    "\n",
    "    # Perform the merge\n",
    "    merged_df1 = pd.merge(out1, mergedcsv1, on=['Country'])\n",
    "    merged_df2 = pd.merge(out2, mergedcsv1, on=['Country'])\n",
    "    merged_df3 = pd.merge(out3, mergedcsv1, on=['Country'])\n",
    "    \n",
    "    # Write the merged DataFrames to CSV files\n",
    "    merged_df1.to_csv(output_file1, index=False)\n",
    "    merged_df2.to_csv(output_file2, index=False)\n",
    "    merged_df3.to_csv(output_file3, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mergedcsv = pd.read_csv(\"csv/CountryAdd_onCurrency_output.csv\")\n",
    "    # Reorder columns\n",
    "    df = mergedcsv[['Country', 'Currency_Code', 'Currency_x', 'Currency_y', 'Units', 'Buy', 'Sell']]\n",
    "    # Write back to CSV\n",
    "    df.to_csv('csv/CountryRearrange.csv', index=False)\n",
    "\n",
    "    out1 = pd.read_csv(\"csv/splitoutput1.csv\")\n",
    "    out2 = pd.read_csv(\"csv/splitoutput2.csv\")\n",
    "    out3 = pd.read_csv(\"csv/splitoutput3.csv\")\n",
    "\n",
    "\n",
    "    output_file1 = 'csv/finaldata1.csv'\n",
    "    output_file2 = 'csv/finaldata2.csv'\n",
    "    output_file3 = 'csv/finaldata3.csv'\n",
    "    mergedcsv1 = pd.read_csv('csv/CountryRearrange.csv')\n",
    "\n",
    "\n",
    "    merge_csv_complex(out1, out2, out3, mergedcsv1, output_file1, output_file2, output_file3)\n",
    "\n",
    "print(\"Final Output Files Created\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
